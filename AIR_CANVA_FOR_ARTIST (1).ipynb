{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Air Canvas For Artist"
      ],
      "metadata": {
        "id": "FdeSJuJZbafN"
      },
      "id": "FdeSJuJZbafN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "Air-Canvas for Artists is an innovative project that merges machine learning with digital art, enabling users to create drawings and paintings in the air. Using hand gestures and movements detected via a camera, the system processes these inputs through machine learning algorithms to draw on a virtual canvas. Built with Python, OpenCV, and Mediapipe, this project offers a novel and intuitive way for artists, designers, and creative professionals to express themselves digitally."
      ],
      "metadata": {
        "id": "UapkfuU3b-Y3"
      },
      "id": "UapkfuU3b-Y3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem Statement :\n",
        "Air-Canvas For Artist aims to address the limitations of traditional digital art creation tools by\n",
        "providing a new and innovative platform for artists and designers to create digital drawings\n",
        "and paintings using the air around them as a canvas.\n",
        "The project utilizes machine learning algorithms based on deep learning techniques to track\n",
        "and interpret human movements in real-time, allowing users to create digital art in a more\n",
        "intuitive and natural way.\n",
        "The goal is to provide an accessible and intuitive tool for digital art creation that enables more\n",
        "people to explore their creative potential, fosters innovation and experimentation, and enables\n",
        "new forms of artistic expression."
      ],
      "metadata": {
        "id": "YsNYJmVNcDXZ"
      },
      "id": "YsNYJmVNcDXZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Objectives :\n",
        "• To push the boundaries of machine learning and computer vision technologies: This\n",
        "project aims to explore the potential of machine learning algorithms for creating\n",
        "interactive and intuitive interfaces for digital art creation. By incorporating deep\n",
        "learning techniques, the project aims to push the boundaries of what is possible in terms\n",
        "of tracking and interpreting human movements in real-time.\n",
        "\n",
        "\n",
        "• To foster creativity and innovation: By providing an accessible and intuitive platform\n",
        "for digital art creation, Air-Canvas For Artist aims to foster creativity and innovation\n",
        "among artists and designers. The project seeks to break down barriers to entry by\n",
        "making digital art creation easy and intuitive, thus enabling more people to explore\n",
        "their creative potential.\n",
        "\n",
        "\n",
        "• To enable new applications in education, design, and rehabilitation: Air-Canvas For\n",
        "Artist aims to explore the potential applications of this technology in a wide range of\n",
        "fields, including education, professional design, and the medical field for\n",
        "rehabilitation purposes. By providing an accessible and intuitive tool for digital art\n",
        "creation, the project has the potential to impact a wide range of industries and\n",
        "applications."
      ],
      "metadata": {
        "id": "P7JDr55qcKFd"
      },
      "id": "P7JDr55qcKFd"
    },
    {
      "cell_type": "code",
      "source": [
        "# All the imports go here\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from collections import deque\n",
        "\n",
        "\n",
        "# Giving different arrays to handle colour points of different colour\n",
        "bpoints = [deque(maxlen=1024)]\n",
        "gpoints = [deque(maxlen=1024)]\n",
        "rpoints = [deque(maxlen=1024)]\n",
        "ypoints = [deque(maxlen=1024)]\n",
        "\n",
        "\n",
        "# These indexes will be used to mark the points in particular arrays of specific colour\n",
        "blue_index = 0\n",
        "green_index = 0\n",
        "red_index = 0\n",
        "yellow_index = 0\n",
        "\n",
        "#The kernel to be used for dilation purpose\n",
        "kernel = np.ones((5,5),np.uint8)\n",
        "\n",
        "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (0, 255, 255)]\n",
        "colorIndex = 0\n",
        "\n",
        "# Here is code for Canvas setup\n",
        "paintWindow = np.zeros((471,636,3)) + 255\n",
        "paintWindow = cv2.rectangle(paintWindow, (40,1), (140,65), (0,0,0), 2)\n",
        "paintWindow = cv2.rectangle(paintWindow, (160,1), (255,65), (255,0,0), 2)\n",
        "paintWindow = cv2.rectangle(paintWindow, (275,1), (370,65), (0,255,0), 2)\n",
        "paintWindow = cv2.rectangle(paintWindow, (390,1), (485,65), (0,0,255), 2)\n",
        "paintWindow = cv2.rectangle(paintWindow, (505,1), (600,65), (0,255,255), 2)\n",
        "\n",
        "cv2.putText(paintWindow, \"CLEAR\", (49, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "cv2.putText(paintWindow, \"BLUE\", (185, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "cv2.putText(paintWindow, \"GREEN\", (298, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "cv2.putText(paintWindow, \"RED\", (420, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "cv2.putText(paintWindow, \"YELLOW\", (520, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "cv2.namedWindow('Paint', cv2.WINDOW_AUTOSIZE)\n",
        "\n",
        "\n",
        "# initialize mediapipe\n",
        "mpHands = mp.solutions.hands\n",
        "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "\n",
        "# Initialize the webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "ret = True\n",
        "while ret:\n",
        "    # Read each frame from the webcam\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    x, y, c = frame.shape\n",
        "\n",
        "    # Flip the frame vertically\n",
        "    frame = cv2.flip(frame, 1)\n",
        "    #hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    frame = cv2.rectangle(frame, (40,1), (140,65), (0,0,0), 2)\n",
        "    frame = cv2.rectangle(frame, (160,1), (255,65), (255,0,0), 2)\n",
        "    frame = cv2.rectangle(frame, (275,1), (370,65), (0,255,0), 2)\n",
        "    frame = cv2.rectangle(frame, (390,1), (485,65), (0,0,255), 2)\n",
        "    frame = cv2.rectangle(frame, (505,1), (600,65), (0,255,255), 2)\n",
        "    cv2.putText(frame, \"CLEAR\", (49, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "    cv2.putText(frame, \"BLUE\", (185, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "    cv2.putText(frame, \"GREEN\", (298, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "    cv2.putText(frame, \"RED\", (420, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "    cv2.putText(frame, \"YELLOW\", (520, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
        "    #frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    # Get hand landmark prediction\n",
        "    result = hands.process(framergb)\n",
        "\n",
        "    # post process the result\n",
        "    if result.multi_hand_landmarks:\n",
        "        landmarks = []\n",
        "        for handslms in result.multi_hand_landmarks:\n",
        "            for lm in handslms.landmark:\n",
        "                # # print(id, lm)\n",
        "                # print(lm.x)\n",
        "                # print(lm.y)\n",
        "                lmx = int(lm.x * 640)\n",
        "                lmy = int(lm.y * 480)\n",
        "\n",
        "                landmarks.append([lmx, lmy])\n",
        "\n",
        "\n",
        "            # Drawing landmarks on frames\n",
        "            mpDraw.draw_landmarks(frame, handslms, mpHands.HAND_CONNECTIONS)\n",
        "        fore_finger = (landmarks[8][0],landmarks[8][1])\n",
        "        center = fore_finger\n",
        "        thumb = (landmarks[4][0],landmarks[4][1])\n",
        "        cv2.circle(frame, center, 3, (0,255,0),-1)\n",
        "        print(center[1]-thumb[1])\n",
        "        if (thumb[1]-center[1]<30):\n",
        "            bpoints.append(deque(maxlen=512))\n",
        "            blue_index += 1\n",
        "            gpoints.append(deque(maxlen=512))\n",
        "            green_index += 1\n",
        "            rpoints.append(deque(maxlen=512))\n",
        "            red_index += 1\n",
        "            ypoints.append(deque(maxlen=512))\n",
        "            yellow_index += 1\n",
        "\n",
        "        elif center[1] <= 65:\n",
        "            if 40 <= center[0] <= 140: # Clear Button\n",
        "                bpoints = [deque(maxlen=512)]\n",
        "                gpoints = [deque(maxlen=512)]\n",
        "                rpoints = [deque(maxlen=512)]\n",
        "                ypoints = [deque(maxlen=512)]\n",
        "\n",
        "                blue_index = 0\n",
        "                green_index = 0\n",
        "                red_index = 0\n",
        "                yellow_index = 0\n",
        "\n",
        "                paintWindow[67:,:,:] = 255\n",
        "            elif 160 <= center[0] <= 255:\n",
        "                    colorIndex = 0 # Blue\n",
        "            elif 275 <= center[0] <= 370:\n",
        "                    colorIndex = 1 # Green\n",
        "            elif 390 <= center[0] <= 485:\n",
        "                    colorIndex = 2 # Red\n",
        "            elif 505 <= center[0] <= 600:\n",
        "                    colorIndex = 3 # Yellow\n",
        "        else :\n",
        "            if colorIndex == 0:\n",
        "                bpoints[blue_index].appendleft(center)\n",
        "            elif colorIndex == 1:\n",
        "                gpoints[green_index].appendleft(center)\n",
        "            elif colorIndex == 2:\n",
        "                rpoints[red_index].appendleft(center)\n",
        "            elif colorIndex == 3:\n",
        "                ypoints[yellow_index].appendleft(center)\n",
        "    # Append the next deques when nothing is detected to avois messing up\n",
        "    else:\n",
        "        bpoints.append(deque(maxlen=512))\n",
        "        blue_index += 1\n",
        "        gpoints.append(deque(maxlen=512))\n",
        "        green_index += 1\n",
        "        rpoints.append(deque(maxlen=512))\n",
        "        red_index += 1\n",
        "        ypoints.append(deque(maxlen=512))\n",
        "        yellow_index += 1\n",
        "\n",
        "    # Draw lines of all the colors on the canvas and frame\n",
        "    points = [bpoints, gpoints, rpoints, ypoints]\n",
        "    for i in range(len(points)):\n",
        "        for j in range(len(points[i])):\n",
        "            for k in range(1, len(points[i][j])):\n",
        "                if points[i][j][k - 1] is None or points[i][j][k] is None:\n",
        "                    continue\n",
        "                cv2.line(frame, points[i][j][k - 1], points[i][j][k], colors[i], 2)\n",
        "                cv2.line(paintWindow, points[i][j][k - 1], points[i][j][k], colors[i], 2)\n",
        "\n",
        "    cv2.imshow(\"Output\", frame)\n",
        "    cv2.imshow(\"Paint\", paintWindow)\n",
        "\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "# release the webcam and destroy all active windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "yri7DkPkbYHM"
      },
      "id": "yri7DkPkbYHM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusion :\n",
        "\n",
        "*   This application might put conventional writing techniques to the test. removes the need to carry a handheld device around in order to take notes and provides a convenient option to accomplish the same while on the road. It will once more serve a greater good by making communication simpler, especially for people who are familiar with them.\n",
        "*   The software is simple enough to use for those who have trouble using the keyboard. Soon, this program's capability will allow for the control of IoT devices.\n",
        "*   Additionally, air painting is possible. With the help of this system, people will be able to interact with the digital world more effectively while wearing smart gear.\n",
        "\n",
        "*   The system will be an excellent software for smart wearables using which people could better interact with the digital world. Augmented Reality can make text come alive. There are some limitations of the system which can be improved in the future.\n"
      ],
      "metadata": {
        "id": "mFmnocMzcSc6"
      },
      "id": "mFmnocMzcSc6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Future Scope:\n",
        "Computer Vision is the science of helping computers perceive and interpret digital pictures\n",
        "such as photos and movies. It's been a decades-long topic of intense investigation. Computer\n",
        "vision is getting better than the human visual cognitive system at spotting patterns from\n",
        "pictures. Computer vision-based technologies have surpassed human doctors' pattern\n",
        "recognition skills in the healthcare industry .Let us examine the status of computer vision\n",
        "technology now and in the future. There are several aspects to consider when computer vision\n",
        "expands its effect on the human world. With further study and fine-tuning, computer vision\n",
        "will be able to do more in the future. The system will be simpler to train and can identify more\n",
        "from photos than it does presently. Computer vision will be used in conjunction with other\n",
        "technologies or subsets of AI to generate more attractive applications. Image captioning apps,\n",
        "for example, may use natural language generation (NLG) to understand things in the\n",
        "environment for visually impaired persons. Computer vision may help create artificial general\n",
        "intelligence (AGI) and artificial superintelligence (ASI) by processing information better than\n",
        "the human visual system. Computer vision is a growing sector linked to virtual and augmented\n",
        "reality (VR and AR). Recent market participants have shown a great interest in VR/AR fusion.\n",
        "This significant growth in attention is mirrored in the release of several cutting-edge technology\n",
        "items."
      ],
      "metadata": {
        "id": "Ya_20cOIbWqo"
      },
      "id": "Ya_20cOIbWqo"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}